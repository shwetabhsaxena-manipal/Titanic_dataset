{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b838f4",
   "metadata": {},
   "source": [
    "# Titanic dataset\n",
    "\n",
    "We will be predicting the likelihood of survival of a passenger with certain features, in the event of Titanic, using data from the passengers who survived.\n",
    "\n",
    "We will use the Titannic dataset procured by Kaggle competition, having the files \"train.csv\" used for training and testing purposes, using logistic regression with regularization. The file \"Titanic.txt\" holds the information regarding the features of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46db302a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the first five training examples printed out:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "The dimensions of this dataset are: (891, 12)\n"
     ]
    }
   ],
   "source": [
    "#import relevant libraries that will be used\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "print(\"Here are the first five training examples printed out:\")\n",
    "print(data.head())\n",
    "print(\"The dimensions of this dataset are:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44cd04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking to see which features have missing values:\n",
      "\n",
      "Age was found to have missing values of the amount 177\n",
      "Cabin was found to have missing values of the amount 687\n",
      "Embarked was found to have missing values of the amount 2\n"
     ]
    }
   ],
   "source": [
    "#Now we see that that we have 891 training examples. Now we have to verify if there are any missing values and which features\n",
    "#have them and how much.\n",
    "\n",
    "print(\"Checking to see which features have missing values:\\n\")\n",
    "for columnName, columnValue in data.iteritems():\n",
    "    if(data[columnName].isnull().any()):\n",
    "        print(columnName, \"was found to have missing values of the amount\", data[columnName].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c277832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is obvious that some of the features are irrelevant to the regression analysis, namely PassengerId, Name and Ticket\n",
    "del data['PassengerId'], data['Name'], data['Ticket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da069d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
      "0         0       3    male  22.0      1      0   7.2500     0        S\n",
      "1         1       1  female  38.0      1      0  71.2833   C85        C\n",
      "2         1       3  female  26.0      0      0   7.9250     0        S\n",
      "3         1       1  female  35.0      1      0  53.1000  C123        S\n",
      "4         0       3    male  35.0      0      0   8.0500     0        S\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       891 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Cabin     891 non-null    object \n",
      " 8   Embarked  891 non-null    object \n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Even though the 'Age' and 'Cabin' have 177 and 687 values missing respectively, they are essential in determining whether a\n",
    "#passenger survived or not. For 'Age' we will choose to replace the NaN values will the mean of all ages [this ensures that\n",
    "#the missing values won't interfere in the learning model's output] and the 'Cabin' NaN value will be changed to '0' in count\n",
    "#which means for any test example, if cabin value is missing, it will not be used as a feature while computing the output.\n",
    "#For 'Embarked' only two missing values are there, we can just replace the NaN values with 0 as well.\n",
    "\n",
    "data['Age'] = data['Age'].fillna(data['Age'].mean())\n",
    "data['Cabin'] = data['Cabin'].fillna('0')\n",
    "data['Embarked'] = data['Embarked'].fillna('0')\n",
    "\n",
    "print(data.head())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5962af34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of changes made to the dataset: 3\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    int64  \n",
      " 3   Age       891 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Cabin     891 non-null    int64  \n",
      " 8   Embarked  891 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 62.8 KB\n",
      "Displaying the info for all columns for sanity check:  None\n",
      "Printing the modified dataset:\n",
      "    Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked\n",
      "0         0       3    1  22.0      1      0   7.2500      0         1\n",
      "1         1       1    2  38.0      1      0  71.2833      2         2\n",
      "2         1       3    2  26.0      0      0   7.9250      0         1\n",
      "3         1       1    2  35.0      1      0  53.1000      2         1\n",
      "4         0       3    1  35.0      0      0   8.0500      0         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHWETA~1\\AppData\\Local\\Temp/ipykernel_1924/2246013458.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Cabin'][i] = string[0]\n"
     ]
    }
   ],
   "source": [
    "#As we can see, the 'Age' column is now non-null. We can see that we have 3 object type features that we need to convert\n",
    "#numercial values. However, in 'Cabin' we can clearly see that most cabin numbers are different, but their first letter shows\n",
    "#which deck they are in, which is obviously a feature that can strongly predict the survivalhood. We will take the first letter\n",
    "#and replace the corresponding value in the dataset.\n",
    "\n",
    "for i in range(891):\n",
    "    string = data['Cabin'][i]\n",
    "    data['Cabin'][i] = string[0]\n",
    "\n",
    "num_change = 0\n",
    "for (columnName, columnData) in data.iteritems():\n",
    "    if(data.dtypes[columnName]==object):\n",
    "        num_change += 1\n",
    "        count = 1\n",
    "        dictionary = {}\n",
    "        for i in range(891):\n",
    "            if(dictionary.get(columnData[i])==None):\n",
    "                if(columnData[i]=='0'): dictionary[columnData[i]] = 0\n",
    "                else: dictionary[columnData[i]] = count\n",
    "                count += 1\n",
    "            else: continue\n",
    "        data[columnName] = data[columnName].replace(dictionary)\n",
    "print(\"The number of changes made to the dataset:\", num_change)\n",
    "print(\"Displaying the info for all columns for sanity check: \", data.info())\n",
    "print(\"Printing the modified dataset:\\n\", data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd30daa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the training sets are: (713, 8) (713, 1)\n",
      "The dimensions of the training sets are: (178, 8) (178, 1)\n"
     ]
    }
   ],
   "source": [
    "#Having successfully pre-processed the data, we can now proceed with the next stage, which is splitting this dataset into\n",
    "#two parts, training and testing set in 80%-20% configuration.\n",
    "\n",
    "xtrain = data[:713]\n",
    "ytrain = np.array(xtrain['Survived']).reshape(713, 1)\n",
    "del xtrain['Survived']\n",
    "print(\"The dimensions of the training sets are:\", xtrain.shape, ytrain.shape)\n",
    "\n",
    "xtest = data[713:]\n",
    "ytest = np.array(xtest['Survived']).reshape(178, 1)\n",
    "del xtest['Survived']\n",
    "print(\"The dimensions of the training sets are:\", xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c870ad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHWETA~1\\AppData\\Local\\Temp/ipykernel_1924/1828463240.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if(X.std(axis=0)[i]!=0): X[columnName] = (X[columnName]-X.mean(axis=0)[i])/X.std(axis=0)[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amended dataset becomes:\n",
      "      Pclass       Sex       Age     SibSp    Parch      Fare   Cabin  Embarked\n",
      "0  0.833679 -0.747923 -0.613714  0.443010 -0.46942 -0.519835 -0.4739 -0.575941\n",
      "1 -1.548738  1.335160  0.615649  0.443010 -0.46942  0.796531  0.4673  0.973667\n",
      "2  0.833679  1.335160 -0.306373 -0.497068 -0.46942 -0.505959 -0.4739 -0.575941\n",
      "3 -1.548738  1.335160  0.385144  0.443010 -0.46942  0.422727  0.4673 -0.575941\n",
      "4  0.833679 -0.747923  0.385144 -0.497068 -0.46942 -0.503389 -0.4739 -0.575941\n"
     ]
    }
   ],
   "source": [
    "#Feature scaling is required as 'Fare' and 'Age' are much bigger than the other int64 values in the training set. We will use\n",
    "#mean normalisation with standard deviation division.\n",
    "def normalise(X):\n",
    "    i = 0\n",
    "    for columnName, columnValue in X.iteritems():\n",
    "        if(X.std(axis=0)[i]!=0): X[columnName] = (X[columnName]-X.mean(axis=0)[i])/X.std(axis=0)[i]\n",
    "        i +=1\n",
    "\n",
    "normalise(xtrain)\n",
    "print(\"The amended dataset becomes:\\n\", xtrain.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b975ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now need to append the bias column of ones for training the model.\n",
    "\n",
    "X0train = np.ones(len(xtrain)).reshape(713, 1)\n",
    "Xtrain = np.append(X0train, xtrain, axis=1).reshape(713, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56837cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we define the sigmoid function, cost function [with regularization] and the gradient descent function.\n",
    "\n",
    "def sigmoid(a):\n",
    "    e = 2.718281828459045\n",
    "    return 1/(1+e**(-a))\n",
    "\n",
    "def computeCost(X, y, theta, lambda1):\n",
    "    theta1 = np.array(theta)\n",
    "    theta1[0] = 0\n",
    "    J = ((-1/m)*(np.sum((ytrain.transpose() @ np.log10(sigmoid(X @ theta))) + ((1-y.transpose()) @ np.log10(1-sigmoid(X @ theta)))))) + (lambda1/(2*m)*np.sum(np.square(theta1)))\n",
    "    return J;\n",
    "\n",
    "def gradientDescent(X, y, theta, alpha, lambda1, iterations, m):\n",
    "    J_history = np.zeros(iterations).reshape(iterations, 1)\n",
    "    for iter in range(iterations):\n",
    "        theta1 = np.array(theta)\n",
    "        theta1[0] = 0\n",
    "        theta = theta - (alpha/m)*((X.transpose() @ (sigmoid(X @ theta)-y))+(lambda1*theta1))\n",
    "        J_history[iter] = computeCost(X, y, theta, lambda1)\n",
    "    return [theta, J_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c5a984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost when the parameters are zeros: 0.3010299956639812\n"
     ]
    }
   ],
   "source": [
    "m = 713\n",
    "lambda1 = 1\n",
    "theta = np.zeros(9).reshape(9, 1)\n",
    "print(\"Cost when the parameters are zeros:\", computeCost(Xtrain, ytrain, theta, lambda1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c98414e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final cost value is: 0.19598021838587754\n"
     ]
    }
   ],
   "source": [
    "#Now we will train the model using the parameters shown below.\n",
    "\n",
    "theta = np.zeros(9).reshape(9, 1)\n",
    "alpha, lambda1, iterations, m = 0.05, 0.5, 2000, 713\n",
    "\n",
    "returned = gradientDescent(Xtrain, ytrain, theta, alpha, lambda1, iterations, m)\n",
    "theta = returned[0]\n",
    "J_history = returned[1]\n",
    "print(\"The final cost value is:\", computeCost(Xtrain, ytrain, theta, lambda1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "638fb891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24ddac51210>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We will also plot the value of the cost function after each iteration, to see the value reach a minimum and converge to a\n",
    "#stabalised value.\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost function history')\n",
    "plt.plot(range(2000), J_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "710ce667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy percentage is: 83.14606741573034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHWETA~1\\AppData\\Local\\Temp/ipykernel_1924/1828463240.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if(X.std(axis=0)[i]!=0): X[columnName] = (X[columnName]-X.mean(axis=0)[i])/X.std(axis=0)[i]\n"
     ]
    }
   ],
   "source": [
    "#As we can see, the model has converged into a constant value, that means our regression model is created sucessfully.\n",
    "#Let's compare the results with the actual values. We will consider our test set and compare our training model values\n",
    "#with the the original. We will check for our accuracy percentage on the test set.\n",
    "\n",
    "X0test = np.ones(len(xtest)).reshape(178, 1)\n",
    "normalise(xtest)\n",
    "Xtest = np.append(X0test, xtest, axis=1).reshape(178, 9)\n",
    "prediction_real = sigmoid(Xtest @ theta)\n",
    "prediction = np.zeros(len(xtest)).reshape(178, 1)\n",
    "accuracy = np.zeros(len(xtest)).reshape(178, 1)\n",
    "for i in range(178):\n",
    "    if(prediction_real[i]>0.7): prediction[i] = 1\n",
    "for i in range(178):\n",
    "    if(prediction[i]==ytest[i]): accuracy[i] = 1\n",
    "print(\"The accuracy percentage is:\", accuracy.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0064a277",
   "metadata": {},
   "source": [
    "We have successfully predicted accurately for about 83% of the passengers in the test set, which is a good score. We didn't make use of multivariate logistic regression, which could make the algorithm slightly more accurate.\n",
    "\n",
    "Another thing to realise is that many of the features many not have collinearity with the target variable [Survived] and hence, those features may confuse the model, making it more inaccurate. Checking each feature with the target variable to access whether is relevant or not needs to be done.\n",
    "\n",
    "Certain considerations were not given, such as while replacing NaN in age, mean of the entire set was taken, while we could have taken the mean in relation to the class [it takes more time to build wealth, which means mean of age in first class is probably more than mean of third class] and the age of each of of the sex in each class [women are usually younger]. The colinearity of the features with the targest variable was not tested either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8352167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
